{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "next_word_prediction_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iP7akNWjC7m"
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ_pNi7TjEsl"
      },
      "source": [
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlZja-vGjEga",
        "outputId": "7aac7769-d3c3-474f-fbce-96ef881aeadc"
      },
      "source": [
        "# load text\n",
        "raw_text = load_doc('/rhyme.txt')\n",
        "print(raw_text)\n",
        "\n",
        "# clean\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sing a song of sixpence,\n",
            "A pocket full of rye.\n",
            "Four and twenty blackbirds,\n",
            "Baked in a pie.\n",
            "\n",
            "When the pie was opened\n",
            "The birds began to sing;\n",
            "Wasn't that a dainty dish,\n",
            "To set before the king.\n",
            "\n",
            "The king was in his counting house,\n",
            "Counting out his money;\n",
            "The queen was in the parlour,\n",
            "Eating bread and honey.\n",
            "\n",
            "The maid was in the garden,\n",
            "Hanging out the clothes,\n",
            "When down came a blackbird\n",
            "And pecked off her nose.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnAsq0hKjES0",
        "outputId": "337d4014-4f61-4bc5-87ce-53c69a76db80"
      },
      "source": [
        "# organize into sequences of characters\n",
        "length = 10\n",
        "sequences = list()\n",
        "for i in range(length, len(raw_text)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = raw_text[i-length:i+1]\n",
        "\t# store\n",
        "\tsequences.append(seq)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTXfiwrJjfsI",
        "outputId": "8552a15b-a4bf-4a87-fd74-4d232d098a57"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sing a song',\n",
              " 'ing a song ',\n",
              " 'ng a song o',\n",
              " 'g a song of',\n",
              " ' a song of ',\n",
              " 'a song of s',\n",
              " ' song of si',\n",
              " 'song of six',\n",
              " 'ong of sixp',\n",
              " 'ng of sixpe',\n",
              " 'g of sixpen',\n",
              " ' of sixpenc',\n",
              " 'of sixpence',\n",
              " 'f sixpence,',\n",
              " ' sixpence, ',\n",
              " 'sixpence, A',\n",
              " 'ixpence, A ',\n",
              " 'xpence, A p',\n",
              " 'pence, A po',\n",
              " 'ence, A poc',\n",
              " 'nce, A pock',\n",
              " 'ce, A pocke',\n",
              " 'e, A pocket',\n",
              " ', A pocket ',\n",
              " ' A pocket f',\n",
              " 'A pocket fu',\n",
              " ' pocket ful',\n",
              " 'pocket full',\n",
              " 'ocket full ',\n",
              " 'cket full o',\n",
              " 'ket full of',\n",
              " 'et full of ',\n",
              " 't full of r',\n",
              " ' full of ry',\n",
              " 'full of rye',\n",
              " 'ull of rye.',\n",
              " 'll of rye. ',\n",
              " 'l of rye. F',\n",
              " ' of rye. Fo',\n",
              " 'of rye. Fou',\n",
              " 'f rye. Four',\n",
              " ' rye. Four ',\n",
              " 'rye. Four a',\n",
              " 'ye. Four an',\n",
              " 'e. Four and',\n",
              " '. Four and ',\n",
              " ' Four and t',\n",
              " 'Four and tw',\n",
              " 'our and twe',\n",
              " 'ur and twen',\n",
              " 'r and twent',\n",
              " ' and twenty',\n",
              " 'and twenty ',\n",
              " 'nd twenty b',\n",
              " 'd twenty bl',\n",
              " ' twenty bla',\n",
              " 'twenty blac',\n",
              " 'wenty black',\n",
              " 'enty blackb',\n",
              " 'nty blackbi',\n",
              " 'ty blackbir',\n",
              " 'y blackbird',\n",
              " ' blackbirds',\n",
              " 'blackbirds,',\n",
              " 'lackbirds, ',\n",
              " 'ackbirds, B',\n",
              " 'ckbirds, Ba',\n",
              " 'kbirds, Bak',\n",
              " 'birds, Bake',\n",
              " 'irds, Baked',\n",
              " 'rds, Baked ',\n",
              " 'ds, Baked i',\n",
              " 's, Baked in',\n",
              " ', Baked in ',\n",
              " ' Baked in a',\n",
              " 'Baked in a ',\n",
              " 'aked in a p',\n",
              " 'ked in a pi',\n",
              " 'ed in a pie',\n",
              " 'd in a pie.',\n",
              " ' in a pie. ',\n",
              " 'in a pie. W',\n",
              " 'n a pie. Wh',\n",
              " ' a pie. Whe',\n",
              " 'a pie. When',\n",
              " ' pie. When ',\n",
              " 'pie. When t',\n",
              " 'ie. When th',\n",
              " 'e. When the',\n",
              " '. When the ',\n",
              " ' When the p',\n",
              " 'When the pi',\n",
              " 'hen the pie',\n",
              " 'en the pie ',\n",
              " 'n the pie w',\n",
              " ' the pie wa',\n",
              " 'the pie was',\n",
              " 'he pie was ',\n",
              " 'e pie was o',\n",
              " ' pie was op',\n",
              " 'pie was ope',\n",
              " 'ie was open',\n",
              " 'e was opene',\n",
              " ' was opened',\n",
              " 'was opened ',\n",
              " 'as opened T',\n",
              " 's opened Th',\n",
              " ' opened The',\n",
              " 'opened The ',\n",
              " 'pened The b',\n",
              " 'ened The bi',\n",
              " 'ned The bir',\n",
              " 'ed The bird',\n",
              " 'd The birds',\n",
              " ' The birds ',\n",
              " 'The birds b',\n",
              " 'he birds be',\n",
              " 'e birds beg',\n",
              " ' birds bega',\n",
              " 'birds began',\n",
              " 'irds began ',\n",
              " 'rds began t',\n",
              " 'ds began to',\n",
              " 's began to ',\n",
              " ' began to s',\n",
              " 'began to si',\n",
              " 'egan to sin',\n",
              " 'gan to sing',\n",
              " 'an to sing;',\n",
              " 'n to sing; ',\n",
              " ' to sing; W',\n",
              " 'to sing; Wa',\n",
              " 'o sing; Was',\n",
              " ' sing; Wasn',\n",
              " \"sing; Wasn'\",\n",
              " \"ing; Wasn't\",\n",
              " \"ng; Wasn't \",\n",
              " \"g; Wasn't t\",\n",
              " \"; Wasn't th\",\n",
              " \" Wasn't tha\",\n",
              " \"Wasn't that\",\n",
              " \"asn't that \",\n",
              " \"sn't that a\",\n",
              " \"n't that a \",\n",
              " \"'t that a d\",\n",
              " 't that a da',\n",
              " ' that a dai',\n",
              " 'that a dain',\n",
              " 'hat a daint',\n",
              " 'at a dainty',\n",
              " 't a dainty ',\n",
              " ' a dainty d',\n",
              " 'a dainty di',\n",
              " ' dainty dis',\n",
              " 'dainty dish',\n",
              " 'ainty dish,',\n",
              " 'inty dish, ',\n",
              " 'nty dish, T',\n",
              " 'ty dish, To',\n",
              " 'y dish, To ',\n",
              " ' dish, To s',\n",
              " 'dish, To se',\n",
              " 'ish, To set',\n",
              " 'sh, To set ',\n",
              " 'h, To set b',\n",
              " ', To set be',\n",
              " ' To set bef',\n",
              " 'To set befo',\n",
              " 'o set befor',\n",
              " ' set before',\n",
              " 'set before ',\n",
              " 'et before t',\n",
              " 't before th',\n",
              " ' before the',\n",
              " 'before the ',\n",
              " 'efore the k',\n",
              " 'fore the ki',\n",
              " 'ore the kin',\n",
              " 're the king',\n",
              " 'e the king.',\n",
              " ' the king. ',\n",
              " 'the king. T',\n",
              " 'he king. Th',\n",
              " 'e king. The',\n",
              " ' king. The ',\n",
              " 'king. The k',\n",
              " 'ing. The ki',\n",
              " 'ng. The kin',\n",
              " 'g. The king',\n",
              " '. The king ',\n",
              " ' The king w',\n",
              " 'The king wa',\n",
              " 'he king was',\n",
              " 'e king was ',\n",
              " ' king was i',\n",
              " 'king was in',\n",
              " 'ing was in ',\n",
              " 'ng was in h',\n",
              " 'g was in hi',\n",
              " ' was in his',\n",
              " 'was in his ',\n",
              " 'as in his c',\n",
              " 's in his co',\n",
              " ' in his cou',\n",
              " 'in his coun',\n",
              " 'n his count',\n",
              " ' his counti',\n",
              " 'his countin',\n",
              " 'is counting',\n",
              " 's counting ',\n",
              " ' counting h',\n",
              " 'counting ho',\n",
              " 'ounting hou',\n",
              " 'unting hous',\n",
              " 'nting house',\n",
              " 'ting house,',\n",
              " 'ing house, ',\n",
              " 'ng house, C',\n",
              " 'g house, Co',\n",
              " ' house, Cou',\n",
              " 'house, Coun',\n",
              " 'ouse, Count',\n",
              " 'use, Counti',\n",
              " 'se, Countin',\n",
              " 'e, Counting',\n",
              " ', Counting ',\n",
              " ' Counting o',\n",
              " 'Counting ou',\n",
              " 'ounting out',\n",
              " 'unting out ',\n",
              " 'nting out h',\n",
              " 'ting out hi',\n",
              " 'ing out his',\n",
              " 'ng out his ',\n",
              " 'g out his m',\n",
              " ' out his mo',\n",
              " 'out his mon',\n",
              " 'ut his mone',\n",
              " 't his money',\n",
              " ' his money;',\n",
              " 'his money; ',\n",
              " 'is money; T',\n",
              " 's money; Th',\n",
              " ' money; The',\n",
              " 'money; The ',\n",
              " 'oney; The q',\n",
              " 'ney; The qu',\n",
              " 'ey; The que',\n",
              " 'y; The quee',\n",
              " '; The queen',\n",
              " ' The queen ',\n",
              " 'The queen w',\n",
              " 'he queen wa',\n",
              " 'e queen was',\n",
              " ' queen was ',\n",
              " 'queen was i',\n",
              " 'ueen was in',\n",
              " 'een was in ',\n",
              " 'en was in t',\n",
              " 'n was in th',\n",
              " ' was in the',\n",
              " 'was in the ',\n",
              " 'as in the p',\n",
              " 's in the pa',\n",
              " ' in the par',\n",
              " 'in the parl',\n",
              " 'n the parlo',\n",
              " ' the parlou',\n",
              " 'the parlour',\n",
              " 'he parlour,',\n",
              " 'e parlour, ',\n",
              " ' parlour, E',\n",
              " 'parlour, Ea',\n",
              " 'arlour, Eat',\n",
              " 'rlour, Eati',\n",
              " 'lour, Eatin',\n",
              " 'our, Eating',\n",
              " 'ur, Eating ',\n",
              " 'r, Eating b',\n",
              " ', Eating br',\n",
              " ' Eating bre',\n",
              " 'Eating brea',\n",
              " 'ating bread',\n",
              " 'ting bread ',\n",
              " 'ing bread a',\n",
              " 'ng bread an',\n",
              " 'g bread and',\n",
              " ' bread and ',\n",
              " 'bread and h',\n",
              " 'read and ho',\n",
              " 'ead and hon',\n",
              " 'ad and hone',\n",
              " 'd and honey',\n",
              " ' and honey.',\n",
              " 'and honey. ',\n",
              " 'nd honey. T',\n",
              " 'd honey. Th',\n",
              " ' honey. The',\n",
              " 'honey. The ',\n",
              " 'oney. The m',\n",
              " 'ney. The ma',\n",
              " 'ey. The mai',\n",
              " 'y. The maid',\n",
              " '. The maid ',\n",
              " ' The maid w',\n",
              " 'The maid wa',\n",
              " 'he maid was',\n",
              " 'e maid was ',\n",
              " ' maid was i',\n",
              " 'maid was in',\n",
              " 'aid was in ',\n",
              " 'id was in t',\n",
              " 'd was in th',\n",
              " ' was in the',\n",
              " 'was in the ',\n",
              " 'as in the g',\n",
              " 's in the ga',\n",
              " ' in the gar',\n",
              " 'in the gard',\n",
              " 'n the garde',\n",
              " ' the garden',\n",
              " 'the garden,',\n",
              " 'he garden, ',\n",
              " 'e garden, H',\n",
              " ' garden, Ha',\n",
              " 'garden, Han',\n",
              " 'arden, Hang',\n",
              " 'rden, Hangi',\n",
              " 'den, Hangin',\n",
              " 'en, Hanging',\n",
              " 'n, Hanging ',\n",
              " ', Hanging o',\n",
              " ' Hanging ou',\n",
              " 'Hanging out',\n",
              " 'anging out ',\n",
              " 'nging out t',\n",
              " 'ging out th',\n",
              " 'ing out the',\n",
              " 'ng out the ',\n",
              " 'g out the c',\n",
              " ' out the cl',\n",
              " 'out the clo',\n",
              " 'ut the clot',\n",
              " 't the cloth',\n",
              " ' the clothe',\n",
              " 'the clothes',\n",
              " 'he clothes,',\n",
              " 'e clothes, ',\n",
              " ' clothes, W',\n",
              " 'clothes, Wh',\n",
              " 'lothes, Whe',\n",
              " 'othes, When',\n",
              " 'thes, When ',\n",
              " 'hes, When d',\n",
              " 'es, When do',\n",
              " 's, When dow',\n",
              " ', When down',\n",
              " ' When down ',\n",
              " 'When down c',\n",
              " 'hen down ca',\n",
              " 'en down cam',\n",
              " 'n down came',\n",
              " ' down came ',\n",
              " 'down came a',\n",
              " 'own came a ',\n",
              " 'wn came a b',\n",
              " 'n came a bl',\n",
              " ' came a bla',\n",
              " 'came a blac',\n",
              " 'ame a black',\n",
              " 'me a blackb',\n",
              " 'e a blackbi',\n",
              " ' a blackbir',\n",
              " 'a blackbird',\n",
              " ' blackbird ',\n",
              " 'blackbird A',\n",
              " 'lackbird An',\n",
              " 'ackbird And',\n",
              " 'ckbird And ',\n",
              " 'kbird And p',\n",
              " 'bird And pe',\n",
              " 'ird And pec',\n",
              " 'rd And peck',\n",
              " 'd And pecke',\n",
              " ' And pecked',\n",
              " 'And pecked ',\n",
              " 'nd pecked o',\n",
              " 'd pecked of',\n",
              " ' pecked off',\n",
              " 'pecked off ',\n",
              " 'ecked off h',\n",
              " 'cked off he',\n",
              " 'ked off her',\n",
              " 'ed off her ',\n",
              " 'd off her n',\n",
              " ' off her no',\n",
              " 'off her nos',\n",
              " 'ff her nose',\n",
              " 'f her nose.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgTU3eJZGStB"
      },
      "source": [
        "# save sequences to file\n",
        "out_filename = 'char_sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZqNWk3aFxCe"
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xLHiwNYjrgN"
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'char_sequences.txt'\n",
        "raw_text = load_doc(in_filename)\n",
        "lines = raw_text.split('\\n')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFrFutp2jrnS",
        "outputId": "89e197c1-cfe1-43e8-ef99-0188573e50ed"
      },
      "source": [
        "# integer encode sequences of characters\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)\n",
        "mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "print(mapping)\n",
        "sequences = list()\n",
        "for line in lines:\n",
        "\t# integer encode line\n",
        "\tencoded_seq = [mapping[char] for char in line]\n",
        "\t# store\n",
        "\tsequences.append(encoded_seq)\n",
        "\n",
        "# vocabulary size\n",
        "vocab_size = len(mapping)\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', \"'\", ',', '.', ';', 'A', 'B', 'C', 'E', 'F', 'H', 'S', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'w', 'x', 'y']\n",
            "{'\\n': 0, ' ': 1, \"'\": 2, ',': 3, '.': 4, ';': 5, 'A': 6, 'B': 7, 'C': 8, 'E': 9, 'F': 10, 'H': 11, 'S': 12, 'T': 13, 'W': 14, 'a': 15, 'b': 16, 'c': 17, 'd': 18, 'e': 19, 'f': 20, 'g': 21, 'h': 22, 'i': 23, 'k': 24, 'l': 25, 'm': 26, 'n': 27, 'o': 28, 'p': 29, 'q': 30, 'r': 31, 's': 32, 't': 33, 'u': 34, 'w': 35, 'x': 36, 'y': 37}\n",
            "Vocabulary Size: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzhpqh8xjrqo"
      },
      "source": [
        "# separate into input and output\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
        "X = array(sequences)\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSODRU8kj33g",
        "outputId": "95870018-b348-4e8c-8d51-f6151139780e"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, epochs=100, verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 75)                34200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 38)                2888      \n",
            "=================================================================\n",
            "Total params: 37,088\n",
            "Trainable params: 37,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "13/13 - 18s - loss: 3.5956 - accuracy: 0.1529\n",
            "Epoch 2/100\n",
            "13/13 - 0s - loss: 3.4402 - accuracy: 0.1905\n",
            "Epoch 3/100\n",
            "13/13 - 0s - loss: 3.1097 - accuracy: 0.1905\n",
            "Epoch 4/100\n",
            "13/13 - 0s - loss: 3.0350 - accuracy: 0.1905\n",
            "Epoch 5/100\n",
            "13/13 - 0s - loss: 3.0034 - accuracy: 0.1905\n",
            "Epoch 6/100\n",
            "13/13 - 0s - loss: 2.9823 - accuracy: 0.1905\n",
            "Epoch 7/100\n",
            "13/13 - 0s - loss: 2.9659 - accuracy: 0.1905\n",
            "Epoch 8/100\n",
            "13/13 - 0s - loss: 2.9585 - accuracy: 0.1905\n",
            "Epoch 9/100\n",
            "13/13 - 0s - loss: 2.9378 - accuracy: 0.1905\n",
            "Epoch 10/100\n",
            "13/13 - 0s - loss: 2.9131 - accuracy: 0.1905\n",
            "Epoch 11/100\n",
            "13/13 - 0s - loss: 2.8970 - accuracy: 0.1980\n",
            "Epoch 12/100\n",
            "13/13 - 0s - loss: 2.8789 - accuracy: 0.2030\n",
            "Epoch 13/100\n",
            "13/13 - 0s - loss: 2.8507 - accuracy: 0.2356\n",
            "Epoch 14/100\n",
            "13/13 - 0s - loss: 2.8178 - accuracy: 0.2180\n",
            "Epoch 15/100\n",
            "13/13 - 0s - loss: 2.7840 - accuracy: 0.2155\n",
            "Epoch 16/100\n",
            "13/13 - 0s - loss: 2.7492 - accuracy: 0.2356\n",
            "Epoch 17/100\n",
            "13/13 - 0s - loss: 2.7034 - accuracy: 0.2356\n",
            "Epoch 18/100\n",
            "13/13 - 0s - loss: 2.6586 - accuracy: 0.2431\n",
            "Epoch 19/100\n",
            "13/13 - 0s - loss: 2.6118 - accuracy: 0.2632\n",
            "Epoch 20/100\n",
            "13/13 - 0s - loss: 2.5529 - accuracy: 0.2657\n",
            "Epoch 21/100\n",
            "13/13 - 0s - loss: 2.5152 - accuracy: 0.2882\n",
            "Epoch 22/100\n",
            "13/13 - 0s - loss: 2.4544 - accuracy: 0.3008\n",
            "Epoch 23/100\n",
            "13/13 - 0s - loss: 2.4188 - accuracy: 0.3058\n",
            "Epoch 24/100\n",
            "13/13 - 0s - loss: 2.4032 - accuracy: 0.3383\n",
            "Epoch 25/100\n",
            "13/13 - 0s - loss: 2.3227 - accuracy: 0.3308\n",
            "Epoch 26/100\n",
            "13/13 - 0s - loss: 2.2862 - accuracy: 0.3634\n",
            "Epoch 27/100\n",
            "13/13 - 0s - loss: 2.2486 - accuracy: 0.3484\n",
            "Epoch 28/100\n",
            "13/13 - 0s - loss: 2.1959 - accuracy: 0.3659\n",
            "Epoch 29/100\n",
            "13/13 - 0s - loss: 2.1540 - accuracy: 0.3684\n",
            "Epoch 30/100\n",
            "13/13 - 0s - loss: 2.0973 - accuracy: 0.3910\n",
            "Epoch 31/100\n",
            "13/13 - 0s - loss: 2.0766 - accuracy: 0.3960\n",
            "Epoch 32/100\n",
            "13/13 - 0s - loss: 2.0170 - accuracy: 0.4311\n",
            "Epoch 33/100\n",
            "13/13 - 0s - loss: 1.9736 - accuracy: 0.4361\n",
            "Epoch 34/100\n",
            "13/13 - 0s - loss: 1.9290 - accuracy: 0.4486\n",
            "Epoch 35/100\n",
            "13/13 - 0s - loss: 1.8993 - accuracy: 0.4486\n",
            "Epoch 36/100\n",
            "13/13 - 0s - loss: 1.8625 - accuracy: 0.4762\n",
            "Epoch 37/100\n",
            "13/13 - 0s - loss: 1.8665 - accuracy: 0.4461\n",
            "Epoch 38/100\n",
            "13/13 - 0s - loss: 1.8076 - accuracy: 0.5013\n",
            "Epoch 39/100\n",
            "13/13 - 0s - loss: 1.7502 - accuracy: 0.5088\n",
            "Epoch 40/100\n",
            "13/13 - 0s - loss: 1.7169 - accuracy: 0.5213\n",
            "Epoch 41/100\n",
            "13/13 - 0s - loss: 1.6849 - accuracy: 0.5464\n",
            "Epoch 42/100\n",
            "13/13 - 0s - loss: 1.6477 - accuracy: 0.5363\n",
            "Epoch 43/100\n",
            "13/13 - 0s - loss: 1.5915 - accuracy: 0.5589\n",
            "Epoch 44/100\n",
            "13/13 - 0s - loss: 1.5396 - accuracy: 0.5739\n",
            "Epoch 45/100\n",
            "13/13 - 0s - loss: 1.5185 - accuracy: 0.6065\n",
            "Epoch 46/100\n",
            "13/13 - 0s - loss: 1.4576 - accuracy: 0.6216\n",
            "Epoch 47/100\n",
            "13/13 - 0s - loss: 1.4389 - accuracy: 0.6140\n",
            "Epoch 48/100\n",
            "13/13 - 0s - loss: 1.4326 - accuracy: 0.6140\n",
            "Epoch 49/100\n",
            "13/13 - 0s - loss: 1.3709 - accuracy: 0.6591\n",
            "Epoch 50/100\n",
            "13/13 - 0s - loss: 1.3314 - accuracy: 0.6642\n",
            "Epoch 51/100\n",
            "13/13 - 0s - loss: 1.2933 - accuracy: 0.6867\n",
            "Epoch 52/100\n",
            "13/13 - 0s - loss: 1.2701 - accuracy: 0.6842\n",
            "Epoch 53/100\n",
            "13/13 - 0s - loss: 1.2230 - accuracy: 0.6842\n",
            "Epoch 54/100\n",
            "13/13 - 0s - loss: 1.1881 - accuracy: 0.7293\n",
            "Epoch 55/100\n",
            "13/13 - 0s - loss: 1.1399 - accuracy: 0.7168\n",
            "Epoch 56/100\n",
            "13/13 - 0s - loss: 1.1173 - accuracy: 0.7293\n",
            "Epoch 57/100\n",
            "13/13 - 0s - loss: 1.0769 - accuracy: 0.7845\n",
            "Epoch 58/100\n",
            "13/13 - 0s - loss: 1.0496 - accuracy: 0.7769\n",
            "Epoch 59/100\n",
            "13/13 - 0s - loss: 1.0124 - accuracy: 0.7769\n",
            "Epoch 60/100\n",
            "13/13 - 0s - loss: 0.9663 - accuracy: 0.8120\n",
            "Epoch 61/100\n",
            "13/13 - 0s - loss: 0.9521 - accuracy: 0.7920\n",
            "Epoch 62/100\n",
            "13/13 - 0s - loss: 0.9171 - accuracy: 0.8070\n",
            "Epoch 63/100\n",
            "13/13 - 0s - loss: 0.8774 - accuracy: 0.8396\n",
            "Epoch 64/100\n",
            "13/13 - 0s - loss: 0.8570 - accuracy: 0.8396\n",
            "Epoch 65/100\n",
            "13/13 - 0s - loss: 0.8392 - accuracy: 0.8246\n",
            "Epoch 66/100\n",
            "13/13 - 0s - loss: 0.8048 - accuracy: 0.8421\n",
            "Epoch 67/100\n",
            "13/13 - 0s - loss: 0.7673 - accuracy: 0.8571\n",
            "Epoch 68/100\n",
            "13/13 - 0s - loss: 0.7703 - accuracy: 0.8622\n",
            "Epoch 69/100\n",
            "13/13 - 0s - loss: 0.7244 - accuracy: 0.8847\n",
            "Epoch 70/100\n",
            "13/13 - 0s - loss: 0.6913 - accuracy: 0.8822\n",
            "Epoch 71/100\n",
            "13/13 - 0s - loss: 0.6603 - accuracy: 0.8847\n",
            "Epoch 72/100\n",
            "13/13 - 0s - loss: 0.6325 - accuracy: 0.8997\n",
            "Epoch 73/100\n",
            "13/13 - 0s - loss: 0.6151 - accuracy: 0.9098\n",
            "Epoch 74/100\n",
            "13/13 - 0s - loss: 0.5877 - accuracy: 0.9248\n",
            "Epoch 75/100\n",
            "13/13 - 0s - loss: 0.5630 - accuracy: 0.9348\n",
            "Epoch 76/100\n",
            "13/13 - 0s - loss: 0.5432 - accuracy: 0.9499\n",
            "Epoch 77/100\n",
            "13/13 - 0s - loss: 0.5213 - accuracy: 0.9373\n",
            "Epoch 78/100\n",
            "13/13 - 0s - loss: 0.5108 - accuracy: 0.9449\n",
            "Epoch 79/100\n",
            "13/13 - 0s - loss: 0.4898 - accuracy: 0.9474\n",
            "Epoch 80/100\n",
            "13/13 - 0s - loss: 0.4675 - accuracy: 0.9499\n",
            "Epoch 81/100\n",
            "13/13 - 0s - loss: 0.4601 - accuracy: 0.9549\n",
            "Epoch 82/100\n",
            "13/13 - 0s - loss: 0.4370 - accuracy: 0.9649\n",
            "Epoch 83/100\n",
            "13/13 - 0s - loss: 0.4072 - accuracy: 0.9649\n",
            "Epoch 84/100\n",
            "13/13 - 0s - loss: 0.3946 - accuracy: 0.9674\n",
            "Epoch 85/100\n",
            "13/13 - 0s - loss: 0.3788 - accuracy: 0.9699\n",
            "Epoch 86/100\n",
            "13/13 - 0s - loss: 0.3699 - accuracy: 0.9699\n",
            "Epoch 87/100\n",
            "13/13 - 0s - loss: 0.3529 - accuracy: 0.9749\n",
            "Epoch 88/100\n",
            "13/13 - 0s - loss: 0.3385 - accuracy: 0.9749\n",
            "Epoch 89/100\n",
            "13/13 - 0s - loss: 0.3218 - accuracy: 0.9774\n",
            "Epoch 90/100\n",
            "13/13 - 0s - loss: 0.3078 - accuracy: 0.9799\n",
            "Epoch 91/100\n",
            "13/13 - 0s - loss: 0.3003 - accuracy: 0.9799\n",
            "Epoch 92/100\n",
            "13/13 - 0s - loss: 0.2907 - accuracy: 0.9850\n",
            "Epoch 93/100\n",
            "13/13 - 0s - loss: 0.2790 - accuracy: 0.9850\n",
            "Epoch 94/100\n",
            "13/13 - 0s - loss: 0.2676 - accuracy: 0.9825\n",
            "Epoch 95/100\n",
            "13/13 - 0s - loss: 0.2589 - accuracy: 0.9875\n",
            "Epoch 96/100\n",
            "13/13 - 0s - loss: 0.2523 - accuracy: 0.9875\n",
            "Epoch 97/100\n",
            "13/13 - 0s - loss: 0.2390 - accuracy: 0.9875\n",
            "Epoch 98/100\n",
            "13/13 - 0s - loss: 0.2285 - accuracy: 0.9925\n",
            "Epoch 99/100\n",
            "13/13 - 0s - loss: 0.2182 - accuracy: 0.9900\n",
            "Epoch 100/100\n",
            "13/13 - 0s - loss: 0.2135 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f4d882910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucFzGFIKj8lG"
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the mapping\n",
        "dump(mapping, open('mapping.pkl', 'wb'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3RbT8AgGXzS"
      },
      "source": [
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# generate a sequence of characters with a language model\n",
        "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of characters\n",
        "\tfor _ in range(n_chars):\n",
        "\t\t# encode the characters as integers\n",
        "\t\tencoded = [mapping[char] for char in in_text]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# one hot encode\n",
        "\t\tencoded = to_categorical(encoded, num_classes=len(mapping))\n",
        "\t\t# predict character\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# reverse map integer to character\n",
        "\t\tout_char = ''\n",
        "\t\tfor char, index in mapping.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_char = char\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += char\n",
        "\treturn in_text\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "# load the mapping\n",
        "mapping = load(open('mapping.pkl', 'rb'))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itIrKKWcGpke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d563890-0eab-4081-ee3f-89f046bf01a4"
      },
      "source": [
        "# test start of rhyme\n",
        "print(generate_seq(model, mapping, 10, 'eating ', 20))\n",
        "# test mid-line\n",
        "print(generate_seq(model, mapping, 10, 'king was i', 20))\n",
        "# test not in original\n",
        "print(generate_seq(model, mapping, 10, 'hello worl', 20))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eating hhss,, Cand ing.. he\n",
            "king was in his counting house\n",
            "hello worl,,, oaentin  hoscllu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehUAUoFSqc8M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}